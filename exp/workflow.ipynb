{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b81244cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from typing import Any, Dict, List, Optional, Literal, TypedDict\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d1f67917",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "ASTRA_API_KEY = os.getenv(\"ASTRA_API_KEY\")\n",
    "DB_ENDPOINT = os.getenv(\"DB_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ff439bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758285378.407604  142308 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash\", api_key=GEMINI_API_KEY, temperature= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b1f3c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I help you today?'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59a98de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiskConversationMemory:\n",
    "    def __init__(self, filename: str = \"chat_memory.pkl\"):\n",
    "        self.filename = Path(filename)\n",
    "        self.memory = ConversationBufferMemory(return_messages=True)\n",
    "        self._load()\n",
    "\n",
    "\n",
    "    def _load(self):\n",
    "        if self.filename.exists():\n",
    "            try:\n",
    "                with open(self.filename, \"rb\") as f:\n",
    "                    self.memory = pickle.load(f)\n",
    "                print(f\"Loaded memory from {self.filename}\")\n",
    "            except Exception as e:\n",
    "                print(\"Failed to load memory, starting fresh:\", e)\n",
    "\n",
    "\n",
    "    def persist(self):\n",
    "        try:\n",
    "            with open(self.filename, \"wb\") as f:\n",
    "                pickle.dump(self.memory, f)\n",
    "                print(f\"Persisted memory to {self.filename}\")\n",
    "        except Exception as e:\n",
    "            print(\"Failed to persist memory:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8710290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_twilio_ingress(state: Dict[str, Any], config, runtime):\n",
    "    payload = state.get(\"twilio_payload\")\n",
    "    if not payload:\n",
    "        return state\n",
    "\n",
    "\n",
    "    text = payload.get(\"Body\") or payload.get(\"Message\") or payload.get(\"text\")\n",
    "    sender = payload.get(\"From\") or payload.get(\"from\")\n",
    "\n",
    "    state[\"user_message\"] = text\n",
    "    state[\"user_meta\"] = {\"sender\": sender, \"raw_payload\": payload}\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f21d40f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 Output: {'twilio_payload': {'Body': 'Hello from Twilio!', 'From': '+911234567890'}, 'user_message': 'Hello from Twilio!', 'user_meta': {'sender': '+911234567890', 'raw_payload': {'Body': 'Hello from Twilio!', 'From': '+911234567890'}}}\n",
      "Test 2 Output: {'twilio_payload': {'Message': 'Hi, using Message field', 'from': '+919876543210'}, 'user_message': 'Hi, using Message field', 'user_meta': {'sender': '+919876543210', 'raw_payload': {'Message': 'Hi, using Message field', 'from': '+919876543210'}}}\n",
      "Test 3 Output: {'twilio_payload': {'text': 'Hello using text field', 'From': '+1111111111'}, 'user_message': 'Hello using text field', 'user_meta': {'sender': '+1111111111', 'raw_payload': {'text': 'Hello using text field', 'From': '+1111111111'}}}\n",
      "Test 4 Output: {}\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    state1 = {\n",
    "        \"twilio_payload\": {\n",
    "            \"Body\": \"Hello from Twilio!\",\n",
    "            \"From\": \"+911234567890\"\n",
    "        }\n",
    "    }\n",
    "    print(\"Test 1 Output:\", node_twilio_ingress(state1))\n",
    "\n",
    "    state2 = {\n",
    "        \"twilio_payload\": {\n",
    "            \"Message\": \"Hi, using Message field\",\n",
    "            \"from\": \"+919876543210\"\n",
    "        }\n",
    "    }\n",
    "    print(\"Test 2 Output:\", node_twilio_ingress(state2))\n",
    "\n",
    "    state3 = {\n",
    "        \"twilio_payload\": {\n",
    "            \"text\": \"Hello using text field\",\n",
    "            \"From\": \"+1111111111\"\n",
    "        }\n",
    "    }\n",
    "    print(\"Test 3 Output:\", node_twilio_ingress(state3))\n",
    "\n",
    "    state4 = {}\n",
    "    print(\"Test 4 Output:\", node_twilio_ingress(state4))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a1129f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_load_vaccination_json(state: Dict[str, Any], config, runtime):\n",
    "    path = state.get(r\"/Users/aashutoshkumar/Documents/Projects/healthgraph-assistant/data/vaccination_schedule.json\", r\"data/vaccination_schedule.json\")\n",
    "    loader = JSONLoader(file_path=path)\n",
    "    docs = loader.load()\n",
    "    state[\"vaccination_docs\"] = docs\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36a99e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_load_outbreak_pdf(state: Dict[str, Any], config: Any = None, runtime: Any = None):\n",
    "    path = state.get(\"outbreak_pdf_path\", \"data/outbreak_report.pdf\")\n",
    "    loader = PyPDFLoader(path)\n",
    "    docs = loader.load_and_split()\n",
    "    state[\"outbreak_docs\"] = docs\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fd1dede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test 1: Loaded 32 docs from /Users/aashutoshkumar/Documents/Projects/healthgraph-assistant/latest_weekly_outbreak/31st_weekly_outbreak.pdf\n",
      "✅ Test 2: Loaded 32 docs from default path\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    state1 = {\n",
    "        \"outbreak_pdf_path\": r\"/Users/aashutoshkumar/Documents/Projects/healthgraph-assistant/latest_weekly_outbreak/31st_weekly_outbreak.pdf\" \n",
    "    }\n",
    "    try:\n",
    "        result1 = node_load_outbreak_pdf(state1)\n",
    "        print(f\"✅ Test 1: Loaded {len(result1['outbreak_docs'])} docs from {state1['outbreak_pdf_path']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Test 1 failed: {e}\")\n",
    "\n",
    "    state2 = {\n",
    "        \"outbreak_pdf_path\": r\"/Users/aashutoshkumar/Documents/Projects/healthgraph-assistant/latest_weekly_outbreak/31st_weekly_outbreak.pdf\" \n",
    "    }\n",
    "    try:\n",
    "        \n",
    "        result2 = node_load_outbreak_pdf(state2)\n",
    "        print(f\"✅ Test 2: Loaded {len(result2['outbreak_docs'])} docs from default path\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Test 2 failed: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26f9e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_build_faiss_index(state: Dict[str, Any], config, runtime):\n",
    "    emb = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "    docs = []\n",
    "    docs.extend(state.get(\"outbreak_docs\", []))\n",
    "    docs.extend(state.get(\"vaccination_docs\", []))\n",
    "\n",
    "\n",
    "    if not docs:\n",
    "        print(\"Nothing found\")\n",
    "        return state\n",
    "\n",
    "\n",
    "    index_dir = Path(state.get(\"index_dir\", \"./faiss_index\"))\n",
    "    index_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    vectorstore = FAISS.from_documents(docs, embedding=emb)\n",
    "    vectorstore.save_local(index_dir)\n",
    "    state[\"local_vectorstore\"] = vectorstore\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "225cd05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_router(state: Dict[str, Any], config: Any = None, runtime: Any = None):\n",
    "\n",
    "    message = state.get(\"user_message\", \"\")\n",
    "    if not message:\n",
    "        state[\"route_decision\"] = {\"route\": \"general_query\", \"reason\": \"empty_message\"}\n",
    "        return state\n",
    "\n",
    "\n",
    "    lower = message.lower()\n",
    "    if any(w in lower for w in [\"urgent\", \"emergency\", \"outbreak\", \"hospital\", \"clinic\", \"immediate\"]):\n",
    "        state[\"route_decision\"] = {\"route\": \"emergency_outbreak\", \"reason\": \"keyword_match\"}\n",
    "        return state\n",
    "\n",
    "\n",
    "    if any(w in lower for w in [\"symptom\", \"fever\", \"cough\", \"vomit\", \"rash\", \"pain\"]):\n",
    "        state[\"route_decision\"] = {\"route\": \"symptom\", \"reason\": \"keyword_match\"}\n",
    "        return state\n",
    "\n",
    "\n",
    "    if any(w in lower for w in [\"vaccine\", \"vaccination\", \"due\", \"schedule\", \"immunize\"]):\n",
    "        state[\"route_decision\"] = {\"route\": \"vaccination_schedule\", \"reason\": \"keyword_match\"}\n",
    "        return state\n",
    "\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a router deciding how to handle user messages. \"\n",
    "        \"Choose one of: emergency_outbreak, symptom, vaccination_schedule, general_query. \"\n",
    "        \"Respond with a JSON object {'route':'...', 'reason':'...'} only.\\n\"\n",
    "        f\"Message: {message}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    decision_text = llm.invoke([{\"role\": \"user\", \"content\": prompt}]).content\n",
    "    import json\n",
    "    try:\n",
    "        decision = json.loads(decision_text)\n",
    "        state[\"route_decision\"] = decision\n",
    "    except Exception:\n",
    "        state[\"route_decision\"] = {\"route\": \"general_query\", \"reason\": \"llm_parse_failed\"}\n",
    "\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "889b6f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 Input: ''\n",
      "Test 1 Output: {'route': 'general_query', 'reason': 'empty_message'}\n",
      "------------------------------------------------------------\n",
      "Test 2 Input: 'This is an urgent hospital emergency'\n",
      "Test 2 Output: {'route': 'emergency_outbreak', 'reason': 'keyword_match'}\n",
      "------------------------------------------------------------\n",
      "Test 3 Input: 'I have fever and cough'\n",
      "Test 3 Output: {'route': 'symptom', 'reason': 'keyword_match'}\n",
      "------------------------------------------------------------\n",
      "Test 4 Input: 'When is my next vaccination due?'\n",
      "Test 4 Output: {'route': 'vaccination_schedule', 'reason': 'keyword_match'}\n",
      "------------------------------------------------------------\n",
      "Test 5 Input: 'Tell me about health services'\n",
      "Test 5 Output: {'route': 'general_query', 'reason': 'llm_parse_failed'}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    test_states = [\n",
    "        {\"user_message\": \"\"},  # empty\n",
    "        {\"user_message\": \"This is an urgent hospital emergency\"},  # emergency_outbreak\n",
    "        {\"user_message\": \"I have fever and cough\"},  # symptom\n",
    "        {\"user_message\": \"When is my next vaccination due?\"},  # vaccination\n",
    "        {\"user_message\": \"Tell me about health services\"},  # fallback -> mock LLM\n",
    "    ]\n",
    "\n",
    "    for i, state in enumerate(test_states, 1):\n",
    "        result = node_router(state)  # use_mock=True avoids real API calls\n",
    "        print(f\"Test {i} Input: {state['user_message']!r}\")\n",
    "        print(f\"Test {i} Output: {result['route_decision']}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "368588a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_emergency_outbreak(state: Dict[str, Any], config: Any = None, runtime: Any = None):\n",
    "    message = state.get(\"user_message\")\n",
    "    if not message:\n",
    "        state[\"response\"] = \"No message provided.\"\n",
    "        return state\n",
    "\n",
    "    vectorstore: Optional[\"FAISS\"] = state.get(\"local_vectorstore\")\n",
    "    if vectorstore is None:\n",
    "        state[\"response\"] = \"Outbreak data not indexed. Please run ingestion first.\"\n",
    "        return state\n",
    "\n",
    "    try:\n",
    "        retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "        conv = ConversationalRetrievalChain.from_llm(\n",
    "            llm=llm,\n",
    "            retriever=retriever,\n",
    "            memory=state.get(\"disk_memory\").memory if state.get(\"disk_memory\") else None\n",
    "        )\n",
    "\n",
    "        result = conv.run(question=message)\n",
    "        state[\"response\"] = result\n",
    "\n",
    "        if state.get(\"disk_memory\"):\n",
    "            state[\"disk_memory\"].persist()\n",
    "\n",
    "    except Exception as e:\n",
    "        state[\"response\"] = f\"Error while handling outbreak query: {e}\"\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "10e838ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from typing import Dict, Any\n",
    "\n",
    "def node_symptom(state: Dict[str, Any], config, runtime):\n",
    "    message = state.get(\"user_message\")\n",
    "\n",
    "    hf_embedding = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "\n",
    "    vector_store = AstraDBVectorStore(\n",
    "        embedding=hf_embedding,\n",
    "        api_endpoint=DB_ENDPOINT,\n",
    "        namespace=\"default_keyspace\",\n",
    "        token=ASTRA_API_KEY,\n",
    "        collection_name=\"medical_v2\",\n",
    "    )\n",
    "\n",
    "    retriever = vector_store.as_retriever()\n",
    "    if retriever is None:\n",
    "        state[\"response\"] = \"Symptom database not connected (Astra DB retriever missing).\"\n",
    "        return state\n",
    "\n",
    "    # ✅ Fix: include both \"context\" and \"question\"\n",
    "    llm_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are a knowledgeable medical assistant. Use the following retrieved content to answer the user’s question accurately.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Instructions:\n",
    "1. Base your answer only on the retrieved content; do not make unsupported guesses.\n",
    "2. Keep explanations clear and professional, suitable for medical guidance.\n",
    "3. If the retrieved information does not answer the question, politely state that the information is unavailable instead of fabricating an answer.\n",
    "4. Avoid unnecessary technical jargon unless the user asks for detailed medical terms.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    # Use RetrievalQA for single-query RAG\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": llm_prompt}\n",
    "    )\n",
    "\n",
    "    result = qa_chain.run(message)\n",
    "    state[\"response\"] = result\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "be6f49cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Question: What are the common symptoms of diabetes?\n",
      "RAG Response: The retrieved content mentions that common symptoms of diabetes can include polyuria (frequent urination), polydipsia (excessive thirst), lethargy, and anorexia (loss of appetite).\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_state = {\n",
    "        \"user_message\": \"What are the common symptoms of diabetes?\",\n",
    "        \"disk_memory\": None\n",
    "    }\n",
    "    config = {}\n",
    "    runtime = {}\n",
    "\n",
    "    updated_state = node_symptom(test_state, config, runtime)\n",
    "\n",
    "    print(\"User Question:\", test_state[\"user_message\"])\n",
    "    print(\"RAG Response:\", updated_state[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848f031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
