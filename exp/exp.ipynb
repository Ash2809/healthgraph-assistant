{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91780733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Workflow compiled successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758361823.364028  725200 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# ----------------------------\n",
    "# Load environment variables\n",
    "# ----------------------------\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "ASTRA_API_KEY = os.getenv(\"ASTRA_API_KEY\")\n",
    "DB_ENDPOINT = os.getenv(\"DB_ENDPOINT\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Disk Memory\n",
    "# ----------------------------\n",
    "class DiskConversationMemory:\n",
    "    def __init__(self, filename: str = \"chat_memory.pkl\"):\n",
    "        self.filename = Path(filename)\n",
    "        self.memory = ConversationBufferMemory(return_messages=True)\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        if self.filename.exists():\n",
    "            try:\n",
    "                with open(self.filename, \"rb\") as f:\n",
    "                    self.memory = pickle.load(f)\n",
    "                print(f\"Loaded memory from {self.filename}\")\n",
    "            except Exception as e:\n",
    "                print(\"Failed to load memory, starting fresh:\", e)\n",
    "\n",
    "    def persist(self):\n",
    "        try:\n",
    "            with open(self.filename, \"wb\") as f:\n",
    "                pickle.dump(self.memory, f)\n",
    "                print(f\"Persisted memory to {self.filename}\")\n",
    "        except Exception as e:\n",
    "            print(\"Failed to persist memory:\", e)\n",
    "\n",
    "# ----------------------------\n",
    "# State Model\n",
    "# ----------------------------\n",
    "class HealthGraphState(BaseModel):\n",
    "    twilio_payload: Optional[Dict[str, Any]] = None\n",
    "    user_message: Optional[str] = None\n",
    "    user_meta: Optional[Dict[str, Any]] = None\n",
    "    vaccination_docs: Optional[Any] = None\n",
    "    outbreak_docs: Optional[Any] = None\n",
    "    local_vectorstore: Optional[Any] = None\n",
    "    disk_memory: Optional[Any] = None\n",
    "    route_decision: Optional[Dict[str, str]] = None\n",
    "    response: Optional[str] = None\n",
    "    vaccination_json_path: Optional[str] = (\n",
    "        r\"/Users/aashutoshkumar/Documents/Projects/healthgraph-assistant/data/vaccination_schedule.json\"\n",
    "    )\n",
    "    outbreak_pdf_path: Optional[str] = (\n",
    "        r\"/Users/aashutoshkumar/Documents/Projects/healthgraph-assistant/latest_weekly_outbreak/31st_weekly_outbreak.pdf\"\n",
    "    )\n",
    "    index_dir: Optional[str] = (\n",
    "        r\"/Users/aashutoshkumar/Documents/Projects/healthgraph-assistant/exp/faiss_index/index.faiss\"\n",
    "    )\n",
    "\n",
    "# ----------------------------\n",
    "# Node Functions\n",
    "# ----------------------------\n",
    "def node_twilio_ingress(state: HealthGraphState) -> HealthGraphState:\n",
    "    payload = state.twilio_payload\n",
    "    if not payload:\n",
    "        return state\n",
    "\n",
    "    text = payload.get(\"Body\") or payload.get(\"Message\") or payload.get(\"text\")\n",
    "    sender = payload.get(\"From\") or payload.get(\"from\")\n",
    "\n",
    "    state.user_message = text\n",
    "    state.user_meta = {\"sender\": sender, \"raw_payload\": payload}\n",
    "    return state\n",
    "\n",
    "def node_load_vaccination_json(state: HealthGraphState) -> HealthGraphState:\n",
    "    loader = JSONLoader(file_path=state.vaccination_json_path)\n",
    "    docs = loader.load()\n",
    "    state.vaccination_docs = docs\n",
    "    return state\n",
    "\n",
    "def node_load_outbreak_pdf(state: HealthGraphState) -> HealthGraphState:\n",
    "    loader = PyPDFLoader(state.outbreak_pdf_path)\n",
    "    docs = loader.load_and_split()\n",
    "    state.outbreak_docs = docs\n",
    "    return state\n",
    "\n",
    "def node_build_faiss_index(state: HealthGraphState) -> HealthGraphState:\n",
    "    hf_embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    docs = state.outbreak_docs or []\n",
    "    if not docs:\n",
    "        print(\"No outbreak documents found to index.\")\n",
    "        return state\n",
    "\n",
    "    index_dir = Path(state.index_dir).parent\n",
    "    index_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    vectorstore = FAISS.from_documents(docs, embedding=hf_embedding)\n",
    "    vectorstore.save_local(str(index_dir))\n",
    "\n",
    "    state.local_vectorstore = vectorstore\n",
    "    print(f\"FAISS index built with {len(docs)} docs and saved to {index_dir}\")\n",
    "    return state\n",
    "\n",
    "def node_router(state: HealthGraphState) -> HealthGraphState:\n",
    "    message = state.user_message or \"\"\n",
    "    if not message:\n",
    "        state.route_decision = {\"route\": \"general_query\", \"reason\": \"empty_message\"}\n",
    "        return state\n",
    "\n",
    "    lower = message.lower()\n",
    "    if any(w in lower for w in [\"urgent\", \"emergency\", \"outbreak\"]):\n",
    "        state.route_decision = {\"route\": \"emergency_outbreak\", \"reason\": \"keyword_match\"}\n",
    "        return state\n",
    "    if any(w in lower for w in [\"symptom\", \"fever\", \"cough\"]):\n",
    "        state.route_decision = {\"route\": \"symptom\", \"reason\": \"keyword_match\"}\n",
    "        return state\n",
    "    if any(w in lower for w in [\"vaccine\", \"vaccination\", \"schedule\"]):\n",
    "        state.route_decision = {\"route\": \"vaccination_schedule\", \"reason\": \"keyword_match\"}\n",
    "        return state\n",
    "\n",
    "    state.route_decision = {\"route\": \"general_query\", \"reason\": \"default\"}\n",
    "    return state\n",
    "\n",
    "def node_emergency_outbreak(state: HealthGraphState) -> HealthGraphState:\n",
    "    if not state.user_message:\n",
    "        state.response = \"No message provided.\"\n",
    "        return state\n",
    "    if not state.local_vectorstore:\n",
    "        state.response = \"Outbreak data not indexed.\"\n",
    "        return state\n",
    "\n",
    "    retriever = state.local_vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    conv = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        memory=state.disk_memory.memory if state.disk_memory else None,\n",
    "        return_source_documents=False,\n",
    "    )\n",
    "    result = conv.run(question=state.user_message)\n",
    "    state.response = result\n",
    "    if state.disk_memory:\n",
    "        state.disk_memory.persist()\n",
    "    return state\n",
    "\n",
    "def node_symptom(state: HealthGraphState) -> HealthGraphState:\n",
    "    hf_embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vector_store = AstraDBVectorStore(\n",
    "        embedding=hf_embedding,\n",
    "        api_endpoint=DB_ENDPOINT,\n",
    "        namespace=\"default_keyspace\",\n",
    "        token=ASTRA_API_KEY,\n",
    "        collection_name=\"medical_v2\",\n",
    "    )\n",
    "    retriever = vector_store.as_retriever()\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"You are a medical assistant.\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\nAnswer clearly.\"\n",
    "    )\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt},\n",
    "    )\n",
    "    state.response = qa_chain.run(state.user_message)\n",
    "    return state\n",
    "\n",
    "def node_vaccination_schedule(state):\n",
    "    message = state.user_message\n",
    "    if not message:\n",
    "        return state\n",
    "\n",
    "    vaccination_json_path = state.vaccination_json_path\n",
    "\n",
    "    try:\n",
    "        with open(vaccination_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            schedule_data = json.load(f)\n",
    "        docs_json_str = json.dumps(schedule_data, ensure_ascii=False, indent=2)\n",
    "    except Exception as e:\n",
    "        state.response = f\"(unable to load vaccination schedule JSON: {e})\"\n",
    "        return state\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        You are an assistant that knows how to infer vaccination due-dates from a vaccination schedule JSON.\n",
    "        Use the provided schedule to answer the question as precisely as possible and, when appropriate, return a short checklist.\n",
    "\n",
    "        SCHEDULE_JSON:\n",
    "        {docs_json_str}\n",
    "\n",
    "        QUESTION:\n",
    "        {message}\n",
    "    \"\"\"\n",
    "\n",
    "    answer = llm.invoke(prompt)\n",
    "    state.response = answer.content  # store only the human-readable text\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_general_query(state: HealthGraphState) -> HealthGraphState:\n",
    "    resp = llm.invoke([{\"role\": \"user\", \"content\": state.user_message}]).content\n",
    "    state.response = resp\n",
    "    return state\n",
    "\n",
    "def node_route_dispatcher(state: HealthGraphState) -> HealthGraphState:\n",
    "    route = state.route_decision[\"route\"] if state.route_decision else \"general_query\"\n",
    "    if route == \"emergency_outbreak\":\n",
    "        return node_emergency_outbreak(state)\n",
    "    if route == \"symptom\":\n",
    "        return node_symptom(state)\n",
    "    if route == \"vaccination_schedule\":\n",
    "        return node_vaccination_schedule(state)\n",
    "    return node_general_query(state)\n",
    "\n",
    "# ----------------------------\n",
    "# Build Workflow\n",
    "# ----------------------------\n",
    "workflow = StateGraph(HealthGraphState)\n",
    "workflow.add_node(\"twilio_ingress\", node_twilio_ingress)\n",
    "workflow.add_node(\"load_vaccination_json\", node_load_vaccination_json)\n",
    "workflow.add_node(\"load_outbreak_pdf\", node_load_outbreak_pdf)\n",
    "workflow.add_node(\"build_faiss_index\", node_build_faiss_index)\n",
    "workflow.add_node(\"router\", node_router)\n",
    "workflow.add_node(\"route_dispatcher\", node_route_dispatcher)\n",
    "workflow.add_node(\"emergency_outbreak\", node_emergency_outbreak)\n",
    "workflow.add_node(\"symptom\", node_symptom)\n",
    "workflow.add_node(\"vaccination_schedule\", node_vaccination_schedule)\n",
    "workflow.add_node(\"general_query\", node_general_query)\n",
    "\n",
    "workflow.add_edge(START, \"twilio_ingress\")\n",
    "workflow.add_edge(\"twilio_ingress\", \"router\")\n",
    "workflow.add_edge(\"router\", \"route_dispatcher\")\n",
    "workflow.add_edge(\"load_vaccination_json\", \"build_faiss_index\")\n",
    "workflow.add_edge(\"load_outbreak_pdf\", \"build_faiss_index\")\n",
    "workflow.add_edge(\"build_faiss_index\", \"route_dispatcher\")\n",
    "workflow.add_edge(\"route_dispatcher\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "print(\"✅ Workflow compiled successfully.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Local Test Runner\n",
    "# ----------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7e140ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/82s4ljdd4vb27_xxzh25mv0w0000gn/T/ipykernel_16424/1092791235.py:190: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  state.response = qa_chain.run(state.user_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response:\n",
      " Okay, I understand you have a fever. Based on the information provided, here's what I can suggest, keeping in mind I am a medical assistant and cannot provide medical advice:\n",
      "\n",
      "1.  **Consider your symptoms:** Do you have any other symptoms besides fever, such as headache, muscle aches, loss of appetite, nausea, vomiting, abdominal pain, or jaundice? Have you traveled recently? These details are important for diagnosis.\n",
      "\n",
      "2.  **If your fever persists:** The provided text mentions \"Pyrexia >3wks with no identified cause after evaluation in hospital for 3d or ≥3 out-patient visits.\" If your fever has been present for an extended period (weeks) and you haven't found a cause, it's important to seek medical attention.\n",
      "\n",
      "3.  **If you have been hospitalized:** The text also mentions \"Nosocomial PUO: Patient hospitalized for >48h with no infection at admission.\" If you developed a fever after being in the hospital for more than 48 hours, this could be a specific type of fever that needs investigation.\n",
      "\n",
      "**Important Considerations:**\n",
      "\n",
      "*   **The information provided discusses various causes of fever, some of which are serious.** It's crucial to get a proper diagnosis from a healthcare professional.\n",
      "*   **Do not self-treat with antibiotics** unless prescribed by a doctor. The text mentions antibiotic resistance is a concern for some infections.\n",
      "\n",
      "**In summary, if you are concerned about your fever, please consult a doctor for proper evaluation and guidance.**\n"
     ]
    }
   ],
   "source": [
    "# Initialize test state\n",
    "disk_mem = DiskConversationMemory()\n",
    "test_state = HealthGraphState(\n",
    "    twilio_payload={\"Body\": \"I have fever what should i do?\"}, \n",
    "    disk_memory=disk_mem\n",
    ")\n",
    "\n",
    "# Run the workflow\n",
    "final_state_dict = app.invoke(test_state)\n",
    "\n",
    "# Print only the human-readable response\n",
    "print(\"Final Response:\\n\", final_state_dict[\"response\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9a9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
